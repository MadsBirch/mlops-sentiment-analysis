{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/madsbirch/Documents/4_semester/mlops/mlops-sentiment-analysis\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/Users/madsbirch/Documents/4_semester/mlops/mlops-sentiment-analysis')\n",
    "print(\"Current working directory: {0}\".format(os.getcwd()))\n",
    "\n",
    "import gzip, json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "\n",
    "\n",
    "from src.data.AmazonReviewData import AmazonReviewsDataset\n",
    "from src.data.make_dataset_temp import get_pandas_DF, sentiment_map, preprocess_data\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# Set device (mps is specific to mac with M1 processor)\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# path to raw data\n",
    "raw_data_path = \"data/raw/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Data exporation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data can be downloaded from: http://jmcauley.ucsd.edu/data/amazon/links.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>I needed a set of jumper cables for my new car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>These long cables work fine for my truck, but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Can't comment much on these since they have no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>I absolutley love Amazon!!!  For the price of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>I purchased the 12' feet long cable set and th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             review\n",
       "0          2  I needed a set of jumper cables for my new car...\n",
       "1          2  These long cables work fine for my truck, but ...\n",
       "2          2  Can't comment much on these since they have no...\n",
       "3          2  I absolutley love Amazon!!!  For the price of ...\n",
       "4          2  I purchased the 12' feet long cable set and th..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_pandas_DF(raw_data_path+'reviews_Automotive_5.json.gz')\n",
    "# subset columns and rename to more intuitive names \n",
    "df = df[['overall', 'reviewText']]\n",
    "df = df.rename(columns={'overall': 'sentiment', 'reviewText': 'review'})\n",
    "  \n",
    "# do sentiment mapping\n",
    "df.sentiment = df.sentiment.apply(sentiment_map)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes are highly imbalanced!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    17895\n",
       "1     1430\n",
       "0     1148\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "train_set, test_set = preprocess_data(raw_data_path, tokenizer=tokenizer, max_len = 256, train_split=0.7)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "valid_loader = DataLoader(test_set, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "  def __init__(self, n_classes: int, dropout: float, bert_out_dim = 768):\n",
    "    super(SentimentClassifier, self).__init__()\n",
    "    self.bert = BertModel.from_pretrained(\"bert-base-cased\")\n",
    "    self.drop = nn.Dropout(dropout)\n",
    "    self.output = nn.Linear(bert_out_dim, n_classes)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    _, pooled_output = self.bert(\n",
    "            input_ids=input_ids, attention_mask=attention_mask, return_dict=False\n",
    "        )\n",
    "    out = self.drop(pooled_output)\n",
    "    return self.output(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = SentimentClassifier(n_classes=3, dropout=0.2).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433258508"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_params = sum([param.nelement()*param.element_size() for param in model.parameters()])\n",
    "mem_bufs = sum([buf.nelement()*buf.element_size() for buf in model.buffers()])\n",
    "mem = mem_params + mem_bufs # in bytes\n",
    "mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/448 [01:51<3:49:01, 30.95s/it]"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "  print(f'[EPOCH]: {epoch:3d}')\n",
    "  \n",
    "  model.train()\n",
    "  for batch in tqdm(train_loader):\n",
    "    \n",
    "    # move data to device\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    \n",
    "    # get model outout and calc loss\n",
    "    output = model(input_ids, attention_mask)\n",
    "    loss = criterion(output, labels)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dfdbeb5e6c2345cb32cc8726be7b62a559fcaacb25273dff681832fd4a016f0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
